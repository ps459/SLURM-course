% $Header: /Users/joseph/Documents/LaTeX/beamer/solutions/generic-talks/generic-ornate-15min-45min.en.tex,v 90e850259b8b 2007/01/28 20:48:30 tantau $

\documentclass{beamer}

% Based on solutions/generic-ornate-15min-45min.en.tex
% and HPCS-UoC-Beamer-master/uoc-beamer-template-1.tex.

% Copyright 2004 by Till Tantau <tantau@users.sourceforge.net>.
%
% In principle, this file can be redistributed and/or modified under
% the terms of the GNU Public License, version 2.
%
% However, this file is supposed to be a template to be modified
% for your own needs. For this reason, if you use this file as a
% template and not specifically distribute it as part of a another
% package/program, I grant the extra permission to freely copy and
% modify this file as you see fit and even to delete this copyright
% notice. 


\mode<presentation>
{
  \usetheme{cambridge}
  %\usetheme{Warsaw}

  \setbeamertemplate{navigation symbols}{}
  \setbeamercovered{transparent}
  % or whatever (possibly just delete it)
}

\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{multicol}

%\usepackage{times}
%\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.


\title[HPC: An introduction] % (optional, use only with long paper titles)
{An Introduction to High Performance Computing and the HPCS}

%\subtitle
%{Presentation Subtitle} % (optional)

\author[SJ Rankin] % (optional, use only with lots of authors)
{Stuart Rankin\\ \texttt{sjr20@cam.ac.uk}}
%{F.~Author\inst{1} \and S.~Another\inst{2}}
% - Use the \inst{?} command only if the authors have different
%   affiliation.

\institute[HPCS, University of Cambridge] % (optional, but mostly needed)
{High Performance Computing Service (http://www.hpc.cam.ac.uk/)\\
University Information Services (http://www.uis.cam.ac.uk/)}
% - Use the \inst command only if there are several affiliations.
% - Keep it simple, no one is interested in your street address.

\date[20/11/2014] % (optional)
{20th November 2014 / UIS Training}

\subject{Courses}
% This is only inserted into the PDF information catalog. Can be left
% out. 



% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}



% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
%\AtBeginSubsection[]
%{
%  \begin{frame}<beamer>{Outline}
%    \tableofcontents[currentsection,currentsubsection]
%  \end{frame}
%}


% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 

%\beamerdefaultoverlayspecification{<+->}


\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Health and Safety}
\begin{columns}[c]
\begin{column}{0.33\textwidth}
\begin{center}
\includegraphics[width=0.8\textwidth,height=0.5\textheight,keepaspectratio]{imgs/health-safety-1.png}\\
\includegraphics[width=0.8\textwidth,height=0.5\textheight,keepaspectratio]{imgs/health-safety-4.png}
\end{center}
\end{column}
\begin{column}{0.33\textwidth}
\begin{center}
\includegraphics[width=0.8\textwidth,height=0.5\textheight,keepaspectratio]{imgs/health-safety-2.png}\\
\includegraphics[width=0.8\textwidth,height=0.5\textheight,keepaspectratio]{imgs/health-safety-5.png}
\end{center}
\end{column}
\begin{column}{0.33\textwidth}
\begin{center}
\includegraphics[width=0.8\textwidth,height=0.5\textheight,keepaspectratio]{imgs/health-safety-3.png}\\
\includegraphics[width=0.8\textwidth,height=0.5\textheight,keepaspectratio]{imgs/health-safety-6.png}
\end{center}
\end{column}
\end{columns}
\end{frame}

\begin{frame}<presentation>{Welcome}
\begin{itemize}
\item{Please sign in on the {\color{red}attendance sheet}.}
\item Please fill in the {\color{red}online feedback} at the end of the course:
      \url{http://feedback.training.cam.ac.uk/ucs/form.php}
\item{Keep your belongings with you.}
%\item Course files can be downloaded from:  \url{www.ucs.cam.ac.uk/training/files}
\item{The printer will not work.}
\item\alert{Please ask questions and let us know if you need assistance.}
\end{itemize}
\end{frame}

\begin{frame}<presentation>{Plan of the Course}
\begin{description}
\item[Part 1:]{Basics}
\item[Part 2:]{High Performance Computing Service}
\item[Part 3:]{Using a HPC Facility}
\item<2>{\alert{With examples!}}
\end{description}
\end{frame}


% - Parts
% - Exactly two or three sections (other than the summary).
% - At *most* three subsections per section.
% - No subsubsections
% - End with summary?
% - Talk about 30s to 2min per frame. 

\part{Basics}
\frame{\partpage}

\begin{frame}{Basics: Outline}
\small
  \tableofcontents[subsectionstyle=hide]%[pausesections]
  % You might wish to add the option [pausesections]
\end{frame}

\section{Why Buy a Big Computer?}

\begin{frame}{Basics: Why Buy a Big Computer?}
  % - A title should summarize the slide in an understandable fashion
  %   for anyone how does not follow everything on the slide itself.

What types of big problem might require a ``Big Computer''?

\begin{description}
\pause
\item[\textit{Compute Intensive:}]{A single problem requiring a large amount of computation.}
\pause
\item[\textit{Memory Intensive:}]{A single problem requiring a large amount of memory.}
\pause
\item[\textit{Data Intensive:}]{Operation on a large amount of data.}
\pause
\item[\textit{High Throughput:}]{Many unrelated problems to be executed over a long period.}
\end{description}
\end{frame}

\begin{frame}{Basics: Compute Intensive Problems}
\begin{itemize}
\item{Distribute the work across multiple CPUs to reduce the execution time as far as possible.}
\pause
\item{Program workload must be \emph{parallelised}.}
\pause
\begin{description}
\item{Parallel programs split into copies (threads).}
\item{Each thread performs a part of the work on its own CPU, concurrently with the others.}
\item{A well-parallelised program will fully exercise as many CPUs as it has threads.}
\end{description}
\pause
\item{The CPUs may need to exchange data rapidly, using specialized hardware.}
\item{Large systems running multiple parallel jobs also need fast access to storage.}
\pause
\item{Many use cases from Physics, Chemistry, Engineering, Astronomy,...}
\item{The traditional domain of \alert{HPC} and the \alert{Supercomputer}.}
\end{itemize}
\end{frame}

\begin{frame}{Basics: Scaling \& Amdahl's Law}
\begin{itemize}
\item{\alert{Using more CPUs is not necessarily faster.}}
\item{Typically parallel codes have a \alert{scaling limit}.}
\item{Partly due to the system overhead of managing more threads, but also to more basic constraints;}
\pause
\item{Amdahl's Law (slightly simplistic model)}
\[
S(N)=\frac{1}{\left(1-p+\frac{p}{N}\right)}
\]
where \begin{align*}p&\text{ is the fraction of the program which can be parallelized}\\
N&\text{ is the number of processors}\\
S(N)&\text{ is the fraction by which the program has sped up}\\&\text{ relative to $N=1$.}
\end{align*}
\end{itemize}
\end{frame}

\begin{frame}{Basics: Amdahl's Law}
\centerline{\includegraphics[width=0.75\textwidth]{imgs/AmdahlsLaw.png}}%
\rightline{\tiny http://en.wikipedia.org/wiki/File:AmdahlsLaw.svg}
\smallskip
\end{frame}

\begin{frame}{The Bottom Line}
\begin{itemize}
\item{Parallelisation requires effort:}
\begin{itemize}
\item{First optimise performance on one CPU.}
\item{Then make $p$ as large as possible.}
\end{itemize}
\item{Eventually using more CPUs is detrimental.}
\end{itemize}
\end{frame}

\begin{frame}{Basics: Data Intensive Problems}
\begin{itemize}
\item{Distribute the data across multiple CPUs to process in a reasonable time.}
\pause
\item{Note that the \emph{same} work may be done on each data segment.}
\pause
\item{Rapid movement of data in and out of (disk) storage becomes important.}
\pause
\begin{description}
\item{\alert{NB Memory and storage are usually different things.}}
\end{description}
\pause
\item{\alert{Big Data} and how to efficiently process it currently occupies much thought.}
\end{itemize}
\end{frame}

\begin{frame}{Basics: High Throughput}
\begin{itemize}
\item{Distribute work across multiple CPUs to reduce the overall execution time as far as possible.}
\item{Workload is trivially (or \emph{embarrassingly}) parallel.}
\pause
\begin{itemize}
\item[$\ast$]{Workload breaks up naturally into \emph{independent} pieces.}
\item[$\ast$]{Each piece is performed by a separate process on a separate CPU (concurrently).}
\end{itemize}
\pause
\item{Emphasis is on throughput over a period, rather than on performance on a single problem.}
\pause
\item{Obviously a supercomputer can do this too.}
\end{itemize}
\end{frame}

\begin{frame}{Basics: Memory Intensive Problems}
\begin{itemize}
\item{Aggregate sufficient memory to enable solution at all.}
\item{Technically more challenging if the program cannot be parallelised efficiently.}
\pause
\item{Historically, the arena of large \alert{SGI} systems.}
\end{itemize}
\end{frame}



%Tasks may be small or large, uniprocessor or multiprocessor, compute-intensive or data-intensive. The set of tasks may be static or dynamic, homogeneous or heterogeneous, loosely coupled or tightly coupled.

%large volumes TB or PB of data and devote most of their processing time to I/O and manipulation of data are deemed data-intensive
%data parallel: concurrent processing of different pieces of data
%big data!
%Compute intensive: Task parallel: concurrent processing of different threads of execution
%embarrassingly parallel: little or no effort is required to separate the problem into a number of parallel tasks
%Amdahl

%If the communication overhead of additional processors outweighs the benefit of adding another processor, one encounters parallel slowdown.

%Condor HTC:  environments that can deliver large amounts of processing capacity over long periods of time. We refer to such environments as High Throughput Computing (HTC) environments.

%The European Grid Infrastructure defines HTC as “a computing paradigm that focuses on the efficient execution of a large number of loosely-coupled tasks. Given the minimal parallel communication requirements, the tasks can be executed on clusters or physically distributed resources using grid technologies. HTC systems are typically optimised to maximise the throughput over a long period of time and a typical metric is jobs per month or year.
%HPC: focuses on the efficient execution of compute intensive, tightly-coupled tasks. Given the high parallel communication requirements, the tasks are typically executed on low latency interconnects which makes it possible to share data very rapidly between a large numbers of processors working on the same problem.''

%Grid computing: distributed, heterogeneous environment that supports collections of users and resources (Virtual Organisations) across traditional administrative, trust and organisational boundaries (real organisations).''

%Integration

%Supercomputer: A supercomputer is a computer at the frontline of contemporary processing capacity – particularly speed of calculation which can happen at speeds of nanoseconds.

%capacity vs capability

%Top500

\section{Inside a Modern Computer}
\begin{frame}{Basics: Inside a Modern Computer}{CPUs in a box}
\only<1>{\centerline{\includegraphics[width=0.8\textwidth]{imgs/lstopo.png}}}%
\only<2->{%
\begin{itemize}
\item<2->{Even small computers now have multiple CPU cores per socket\hfill\\
\visible<3->{\alert{$\implies{}$each socket contains a Symmetric Multi-Processor (SMP).}}}
\item<4->{Larger computers have multiple sockets (each with local memory)\hfill\\
\visible<5->{\alert{$\implies{}$Non-Uniform Memory Architecture (NUMA).}}}
\item<6->{CPU cores also have vector (data-parallel) acceleration (SSE/AVX).}
\item<7->{\alert{Today's ordinary computer is yesterday's supercomputer (with much of the same complication).}}
\end{itemize}
}%
\end{frame}

\section{How to Build a Supercomputer}
\begin{frame}{Basics: How to Build a Supercomputer}
\only<1,2>{\begin{itemize}
\item{A supercomputer aggregates contemporary CPUs to obtain increased computing power.}
\pause
\item{Usually today these are \alert{clusters}.}
\end{itemize}}
\only<3->{\begin{enumerate}
\item{Take some (multicore) CPUs and add some memory.}
\begin{itemize}
\item<4->{Could be an off-the-shelf server, or something more special.}
\item<5->{A NUMA multiprocessor building block: a \alert{node}.}
\item<6->{All CPU cores (unequally) share the node memory\hfill\\
\visible<7->{$\implies{}$the node is a \alert{shared memory} multiprocessor.}}
\end{itemize}
\end{enumerate}
}
\end{frame}

\begin{frame}{Basics: How to Build a Supercomputer}
\begin{tabular}{ll}
\parbox[c]{0.5\textwidth}{\begin{enumerate}
\setcounter{enumi}{1}
\item{Connect the nodes with a \alert{network}\pause\alert{ or networks:}}
\pause
\begin{description}
\item[Gbit Ethernet:]{\alert{100 MB/sec}}
\pause
\item[FDR Infiniband:]{\alert{5 GB/sec}}
\end{description}
\pause
\null\par
Faster network is for \alert{inter-CPU communication across nodes}.\par
\pause
Slower network is for \alert{management} and \alert{provisioning}.\par
\pause
\alert{Storage} may use either.
\end{enumerate}}
&\vbox to 0pt{\vss\vskip 0.25cm\leftline{\includegraphics[height=0.85\textheight]{imgs/coreib.jpg}}\vss}\\
\end{tabular}
\end{frame}

% Choice: how tightly to couple the nodes - one big shared memory, or lots of distributed separate memories?
%pthreads, OpenMP
%MPI

\begin{frame}{Basics: How to Build a Supercomputer}
\begin{enumerate}
\setcounter{enumi}{2}
\item{Logically bind the nodes}
\begin{itemize}
\item{Clusters consist of distinct nodes (i.e. separate Linux computers)\hfill\\
on common private network(s) and managed centrally.}
\pause
\begin{itemize}
\item[$\ast$]{Clusters are \alert{distributed memory} machines.\hfill\\
\pause
\alert{Each task sees only its local node (without help).}}
\pause
\item[$\ast$]{\color{red}Each task must fit within a single node's memory.}
\end{itemize}
\pause
\item{More expensive machines logically bind nodes into a single Linux system.}
\begin{itemize}
\item[$\ast$]{E.g.\ SGI UV.}
\item[$\ast$]{These are \alert{shared memory} machines.}
\item[$\ast$]{Logically one big node (but very non-uniform).}
\end{itemize}
\end{itemize}
\end{enumerate}
\end{frame}

\section{Programming a Multiprocessor Machine}
\begin{frame}{Basics: Programming a Multiprocessor Machine}
\only<1-4>{\begin{itemize}
\item{Non-parallel (serial) code}
\begin{itemize}
\pause
\item[$\ast$]{\alert{For a single node as for a workstation.}}
\pause
\item[$\ast$]{Typically \alert{run as many copies per node as cores}, assuming node memory is sufficent.}
\pause
\item[$\ast$]{\alert{Replicate across multiple nodes.}}
\end{itemize}
\end{itemize}}
\only<5->{\begin{itemize}
\item{Parallel code}
\begin{itemize}
\item<6->[$\ast$]{\alert{Shared memory methods within a node.}\hfill\\
E.g. pthreads, OpenMP.}
\item<7->[$\ast$]{\alert{Distributed memory methods between nodes.}\hfill\\
MPI.}
\end{itemize}
\end{itemize}}
\end{frame}

%\section{Coprocessors}
%\begin{frame}{Basics: Coprocessors}{GPU computing}
%\end{frame}
%
%\section{Cluster Storage}
%\begin{frame}{Basics: Cluster Storage}{Data}
%\end{frame}
%
%\section{Resource Allocation}
%\begin{frame}{Basics: Resource Allocation}{Job scheduling}
%\end{frame}

\section*{Summary}

\begin{frame}{Basics: Summary}

  % Keep the summary *very short*.
  \begin{itemize}
  \item<1->{\alert{Why have a supercomputer?}}
  \begin{itemize}\item<2->{Big problems, long problems, many problems, big data.}\end{itemize}
  \item<3->{Most current supercomputers are \alert{clusters} of separate \alert{nodes}.}
  \item<4->{Each node has \alert{multiple cores} and \alert{non-uniform shared memory}.}
  \item<5->{\alert{Parallel} code uses shared memory (\alert{pthreads/OpenMP}) within a node, distributed memory (\alert{MPI}) between nodes.}
  \item<6->{\alert{Non-parallel} code uses the memory of one node, but may be copied across many.}
  \end{itemize}
  
\end{frame}

\part{The High Performance Computing Service}
\frame{\partpage}

\begin{frame}{HPCS: Outline}
\vskip -\bigskipamount
\small\tableofcontents[subsectionstyle=hide]%[pausesections]
  % You might wish to add the option [pausesections]
\end{frame}

\begin{frame}{HPCS: A Brief History}
\begin{description}
\item[\alert{Mission:}]{Delivery and support of a large HPC resource for use by the University of Cambridge research community.}
\item[\alert{Self-funding:}]{Paying and non-paying service levels.}
\item[\alert{User base:}]{Includes DiRAC (STFC) and industrial users.}
\item<2->[\alert{Plus:}]{Hosted clusters and research projects.}
\end{description}
\end{frame}

\section{A Brief History}
\begin{frame}{HPCS: A Brief History}
\begin{description}
\item[1997]{76.8 Gflop/s}
\item[2002]{1.4 Tflop/s}
\item[2006]{18.27 Tflop/s}
\item[2010]{30 Tflop/s}
\item[2012]{183.38 Tflop/s}
\item[2013]{$183.38\,\mbox{CPU}{}+ 239.90\,\mbox{GPU}$ Tflop/s}
\end{description}
\end{frame}

\begin{frame}<presentation>{Darwin1 (2006--2012)}
\centerline{\includegraphics[width=0.875\textwidth]{imgs/darwin.jpg}}%
\smallskip
\end{frame}

\begin{frame}<presentation>{Darwin3 (2012)(b) \& Wilkes (2013)(f)}
\centerline{\includegraphics[width=0.95\textwidth]{imgs/MLDC-big.jpg}}%
\smallskip
\end{frame}

\section{Darwin - an Infiniband CPU Cluster}
\begin{frame}{Darwin: an Infiniband CPU Cluster}
\begin{itemize}
\item{Each compute node:}
\begin{itemize}
\item[$\ast$]{\only<1>{2x8 cores, Intel Sandy Bridge 2.6 GHz.}\only<2>{{\color{red}16 cores}}}
\item[$\ast$]{\only<1>{$64\,\text{GB}$ RAM ($63900\,\text{MB}$ usable).}\only<2>{{\color{red}$63900\,\text{MB}$}}}
\item[$\ast$]{\only<1>{$56\,\text{Gb/sec}$ (4X FDR) Infiniband.}\only<2>{\color{red}$5\,\text{GB/sec}$ Infiniband (for MPI and storage)}}
\end{itemize}
\item{600 compute nodes (300 belong to Cambridge).}
\item{8 login nodes (\alert{login.hpc.cam.ac.uk}).}
\end{itemize}
\end{frame}

\section{Wilkes - a Dual-Rail Infiniband GPU Cluster}
\begin{frame}{Wilkes: a Dual-Rail Infiniband GPU Cluster}
\begin{itemize}
\item{Each compute node:}
\begin{itemize}
\item[$\ast$]{\only<1>{$2\times\text{NVIDIA Tesla K20c GPU.}$}\only<2->{\color<2->{red}2 GPUs}}
\item[$\ast$]{\only<1>{2x6 cores, Intel Ivy Bridge 2.6 GHz.}\only<2->{{\color{red}12 cores}}}
\item[$\ast$]{\only<1>{$64\,\text{GB}$ RAM ($63900\,\text{MB}$ usable).}\only<2->{{\color{red}$63900\,\text{MB}$}}}
\item[$\ast$]{\only<1>{$2\times56\,\text{Gb/sec}$ (4X FDR) Infiniband.}\only<2->{\color{red}$2\times5\,\text{GB/sec}$ Infiniband (for MPI and storage)}}
\end{itemize}
\item{128 compute nodes.}
\item{8 login nodes (\alert{login.hpc.cam.ac.uk}).}
\item<3->{Environment shared with Darwin (same filesystems, user environment, scheduler).}
\end{itemize}
\end{frame}

\begin{frame}{HPCS Production Cluster Schematic}
\centerline{\includegraphics[width=0.95\textwidth]{imgs/cluster.png}}%
\end{frame}

\section{Storage}
\begin{frame}{HPCS: Storage}
\begin{itemize}
\item{$2.6\,\text{PB}$ split across 5 filesystems.}
\item{Lustre cluster filesystem:}
\begin{itemize}
\item[$\ast$]{Multiple RAID6 back-end disk volumes.}
\item[$\ast$]{Multiple object storage servers.}
\item[$\ast$]{Single metadata server.}
\pause
\item[$\ast$]{\alert{$4\,\text{GB/sec}$ overall read or write.}}
\pause
\item[$\ast$]{\alert{Prefers big read/writes over small.}}
\end{itemize}
\pause
\item{\alert{Always growing.}}
\end{itemize}
\end{frame}

\section{Service Levels}
\begin{frame}{HPCS: Service Levels}
\begin{description}
\visible<1-4>{\item[\textbf{Service Level 1}]{Paying, intended for large projects with long-term, consistent requirement.}}
\begin{itemize}
\visible<2-4>{\item{\alert{Guaranteed fraction of resources per quarter.}}}
\end{itemize}
\visible<1-5>{\item[\textbf{Service Level 2}]{Paying, intended for medium-sized projects with irregular requirement.}}
\begin{itemize}
\visible<3-5>{\item{\alert{High priority, but no guarantees; \emph{ad hoc}.}}}
\end{itemize}
\visible<1-4>{\item[\textbf{Service Level 3}]{Non-paying, intended for interim or pump priming, small-scale use.}}
\begin{itemize}
\visible<4>{\item{\alert{Low priority, limited usage (200,000 Darwin core hours) per quarter.}}}
\end{itemize}
\end{description}
\end{frame}

\begin{frame}{HPCS: Service Levels}
\begin{description}
\item[\textbf{Service Level 4}]{Non-paying, for when nothing else is available.}
\pause
\item{\alert{Very low priority, very restricted, very limited. Best efforts continuation.}}
\end{description}
\end{frame}

\section{Other Activities}
\begin{frame}{HPCS: Other Activities}
\begin{itemize}
\item{Hosted clusters\hfill\\
\qquad e.g.\ \alert{MRC BSU}, \alert{Cardiovascular Epidemiology}, \alert{Whittle Lab}.}
\pause
\item{Research projects\hfill\\
\qquad e.g.\ \alert{Square Kilometre Array}, \alert{Jaguar Land Rover}.}
\end{itemize}
\end{frame}

\section{Future Developments}
\begin{frame}{HPCS: Future Developments}
\begin{itemize}
\item{Closer integration with UIS services.}
\item{New storage-oriented services}
\item{Relocation in early 2015 to the West Cambridge Data Centre.}
\pause
\begin{itemize}
\item{\alert{End of January 2015 for $\tilde{}$6 weeks.}}
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{The West Cambridge Data Centre}
\centerline{\includegraphics[width=1.0\textwidth]{imgs/WCDC2.jpg}}
\end{frame}

\section{How To Apply}
\begin{frame}{HPCS: How To Apply}
\begin{itemize}
\item{Complete the application form:\hfill\\
\qquad\alert{http://www.hpc.cam.ac.uk/HPC-Application.doc}}
\item{Email it to \alert{support@hpc.cam.ac.uk}.}
\item{The PI should be someone senior enough to have funding.\hfill\\
\qquad E.g.\ \alert{supervisor}, \alert{head of research group}.}
\pause
\item{\color{red}Funding is not necessary.}
\pause
\item{Please email \alert{support@hpc.cam.ac.uk} for all support issues.}
\item{Further information can be found on the web site:\hfill\\
\qquad \alert{http://www.hpc.cam.ac.uk}}
\end{itemize}
\end{frame}

\part{Using HPC}
\frame{\partpage}

\begin{frame}{Using HPC: Outline}
\small
  \tableofcontents[subsectionstyle=hide]%[pausesections]
  % You might wish to add the option [pausesections]
\end{frame}

\section{Security}
\begin{frame}{Using HPC: Security}
\begin{itemize}
\item{Cambridge IT is under constant attack by would-be intruders.}
\pause
\item{Big systems are big, juicy targets.}
\pause
\item{Your data and research career is threatened by intruders.}
\pause
\item{\alert{Don't let intruders in.}}
\end{itemize}
\end{frame}

\begin{frame}{Using HPC: Security}
\begin{enumerate}
\item{Keep your password (or private key passphrase) safe.}
\pause
\item{Keep the software on your laptops and PCs up to date.}
\pause
\item{Don't share accounts.}
\pause
\item{Never connect from untrusted machines (e.g. internet caf\'es).}
\pause
\item{Always use SSH (never rlogin or telnet).}
\pause
\item{Never, ever do ``xhost +''.}
\end{enumerate}
\end{frame}

\section{Connecting}
\begin{frame}{Using HPC: Connecting}
\begin{itemize}
\item SSH secure protocol only.\hfill\\
\visible<2->{\alert{Supports login, file transfer, remote desktop\ldots}}
\item<3-> HPCS allows access from registered IP addresses only.\hfill\\
\visible<4->{\alert{Almost all Cambridge University addresses already registered.}}
\visible<5->{\alert{Connection from home possible via your departmental gateway.}}
\end{itemize}
\end{frame}

\subsection{Windows Clients}
\begin{frame}{Connecting: Windows Clients}
\begin{itemize}
\item<1-5> putty, pscp, psftp\hfill\\
\alert{\small http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html}
\item<2-5> WinSCP\hfill\\
\alert{\small http://winscp.net/eng/download.php}
\item<3-5> TurboVNC \alert{\small (remote desktop, 3D optional)}\hfill\\
\alert{\small http://sourceforge.net/projects/turbovnc/files/}
\item<4-5> Cygwin \visible<5>{\alert{\small (provides an application environment similar to Linux)}}\hfill\\
\alert{\small http://cygwin.com/install.html}\hfill\\
\visible<5>{\alert{\small Includes X server for displaying graphical applications running remotely.}}
\item<6> MobaXterm\hfill\\
\alert{\small http://http://mobaxterm.mobatek.net/}
\end{itemize}
\end{frame}

\subsection{Linux/MacOSX/UNIX Clients}
\begin{frame}{Connecting: Linux/MacOSX/UNIX Clients}
\begin{itemize}
\item {\color<2->{red}ssh}, scp, sftp, {\color<2->{red}rsync}\hfill\\
\alert{\small Installed (or installable).}
\item<3-> TurboVNC \alert{\small (remote desktop, 3D optional)}\hfill\\
\alert{\small http://sourceforge.net/projects/turbovnc/files/}
\item<4-> On MacOSX, install \alert{XQuartz} to display remote graphical applications.\hfill\\
\alert{\small http://xquartz.macosforge.org/landing/}
\end{itemize}
\end{frame}

\subsection{Login}
\begin{frame}{Connecting: Login}
\begin{itemize}
\item From Linux/MacOSX/UNIX (or Cygwin):\hfill\\
\alert{ssh -Y \textbf{abc123}@login.hpc.cam.ac.uk}
\pause
\item From graphical clients:\hfill\\
Host: \alert{login.hpc.cam.ac.uk}\hfill\\
Username: \alert{\textbf{abc123}} (your CRSid)
\pause
\item login.hpc will map to a random login node\hfill\\
\alert{i.e. one of login-sand1, login-sand2,\,\ldots\,, login-sand8}\hfill\\
\uncover<4->{{\color{red}NB Not darwin.hpc.}}
\item<5->Non-registered addresses will fail with ``Connection refused''.
\item<6->Similarly for other systems (e.g.\ cardio-login.hpc, login-mrc-bsu.hpc,\ldots). 
\end{itemize}
\end{frame}

\begin{frame}{Connecting: First time login}
\begin{itemize}
\item{The first connection to a particular hostname produces the following:}
\begin{semiverbatim}\footnotesize
The authenticity of host 'login-sand2.hpc.cam.ac.uk (131.111.1.214)' can't be established.

RSA key fingerprint is

{\color<2->{red}0b:ef:59:90:fb:13:4a:c9:56:82:7b:cd:4b:2b:e1:3b}.

Are you sure you want to continue connecting (yes/no)? {\color<3->{red}yes}

Warning: Permanently added 'login-sand2.hpc.cam.ac.uk' (RSA) to the list of known hosts.
\end{semiverbatim}
\smallskip\item{\alert{One should always check the fingerprint before typing ``yes''.}}
\item{Graphical SSH clients should ask a similar question.}
\item{Designed to detect fraudulent servers.}
\end{itemize}
\end{frame}

\begin{frame}{MobaXterm SSH (Windows)}
\only<1>{\begin{center}
\centerline{\includegraphics[height=0.8\textheight]{imgs/mobaxterm-SSH-settings2.png}}
\end{center}}
\only<2>{\begin{center}
\centerline{\includegraphics[height=0.8\textheight]{imgs/mobaxterm-SSH-session.png}}
\end{center}}
\end{frame}

\subsection{File Transfer}
\begin{frame}{Connecting: File Transfer}
\begin{itemize}
\item From Linux/MacOSX/UNIX (or Cygwin):\hfill\\
\alert{\footnotesize rsync -av \textbf{old\_directory/} abc123@login.hpc.cam.ac.uk:scratch/new\_directory}\hfill\\
copies contents of old\_directory to $\tilde{}\text{/scratch/new\_directory}$.\hfill\\\smallskip
\pause
\alert{\footnotesize rsync -av \textbf{old\_directory} abc123@login.hpc.cam.ac.uk:scratch/new\_directory}\hfill\\
copies old\_directory (and contents) to $\tilde{}\text{/scratch/new\_directory/old\_directory}$.\hfill\\
\pause
\begin{itemize}
\item[$\ast$]Rerun to update or resume after interruption.
\item[$\ast$]All transfers are checksummed.
\item[$\ast$]For transfers in the opposite direction, place the remote machine as the first argument.
\end{itemize}
\pause
\item With graphical clients, connect as before and drag and drop.
\end{itemize}
\end{frame}

\subsection{Remote Desktop}
\begin{frame}[fragile]{Connecting: Remote Desktop}
\begin{itemize}
\item First time starting a remote desktop:
\begin{semiverbatim}
\footnotesize
[sjr20@{\color{red}login-sand2} ~]\$ vncserver

You will require a password to access your desktops.

Password: 
Verify:   
Would you like to enter a view-only password (y/n)? n

New 'X' desktop is {\color{red}login-sand2:8}

Starting applications specified in /home/sjr20/.vnc/xstartup.turbovnc
Log file is /home/sjr20/.vnc/login-sand2:8.log
\end{semiverbatim}
\smallskip\item<2->\alert{For 3D graphics sessions, use {\color{red}login-gfx1} or {\color{red}login-gfx2}.}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Connecting: Remote Desktop}
\begin{itemize}
\item Remote desktop already running:
\begin{semiverbatim}
\footnotesize
[sjr20@login-sand2 ~]\$ vncserver -list

TurboVNC server sessions:

X DISPLAY #     PROCESS ID
:8              12745
\end{semiverbatim}
\smallskip\item Kill it:
\begin{semiverbatim}
\footnotesize
[sjr20@login-sand2 ~]\$ vncserver -kill :8
Killing Xvnc process ID 12745
\end{semiverbatim}
\smallskip\item\alert{Typically you only need {\color{red}one} remote desktop.}
\item\alert{Keeps running until killed, or the node reboots.}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Connecting: Remote Desktop}
\begin{itemize}
\item To connect to the desktop from Linux:
\begin{semiverbatim}
\scriptsize
[sjr20@themis ~]\$ vncviewer -via sjr20@{\color<2->{red}login-sand2}.hpc.cam.ac.uk localhost:{\color<2->{red}8}
Connected to RFB server, using protocol version 3.8
Enabling TightVNC protocol extensions
Performing standard VNC authentication
Password:
\end{semiverbatim}
\smallskip
\item{\alert{Press F8 to bring up the control panel.}}
\end{itemize}
\end{frame}

\begin{frame}{HPCS TurboVNC Session}
\begin{center}
\centerline{\includegraphics[width=0.85\textwidth]{imgs/linux-turbovnc.png}}
\end{center}
\end{frame}

\begin{frame}{Linux TurboVNC Control Panel}
\begin{center}
\centerline{\includegraphics[height=0.8\textheight]{imgs/linux-turbovnc-F8.png}}
\end{center}
\end{frame}

\begin{frame}{Connecting: Remote Desktop (MobaXterm)}
\only<1>{\begin{center}
\centerline{\includegraphics[height=0.8\textheight]{imgs/mobaxterm-turbovnc.png}}
\end{center}}
\only<2>{\begin{center}
\includegraphics[height=0.8\textheight]{imgs/mobaxterm-vgl-turbovnc.png}
\end{center}}
\end{frame}

\begin{frame}{3D Remote Visualization}
\only<1>{\begin{center}
\includegraphics[height=0.8\textheight]{imgs/vgl-turbovnc.png}
\end{center}}
\only<2>{
\begin{itemize}
\item{Choose either \alert{login-gfx1} or \alert{login-gfx2}.}
\item{Launch any application requiring 3D (OpenGL) with \alert{vglrun}.}
\item{May need to adjust the compression level for your network connection.}
\end{itemize}
}
\end{frame}

%\subsection{Tunnelling}
%\begin{frame}{Connecting: Tunnelling}
%\end{frame}

\section{User Environment}
\begin{frame}{Using HPC: User Environment}
\begin{itemize}
\item<1,4>{\visible<1>{Scientific Linux 6.5 (}\alert<1>{{\color<4>{red}Red Hat Enterprise Linux 6}\visible<1>{.5 rebuild)}}}
\begin{itemize}
\item{\visible<1>{bash}}
\item{\visible<1>{GNOME2 desktop \alert{(if you want)}}}
\end{itemize}
\item<1,4>{\visible<1>{Lustre 2.4.1 (patched), Mellanox OFED 2.3,} {\color<4>{red}CUDA 6}\visible<1>{.5}}
\item<2->{But you don't need to know that. \visible<3->{\alert{(Probably\ldots)}}}
\end{itemize}
\end{frame}

\subsection{Filesystems}
\begin{frame}{User Environment: Filesystems}
\begin{itemize}
\item{\alert{/home/abc123}}
\begin{itemize}
\item{40GB soft quota (45GB hard).}
\item{Visible equally from all nodes.}
\item{Single storage server.}
\item{Backed up nightly to tape.}
\item{Not intended for job outputs or large/many input files.}
\end{itemize}
\item{\alert{/scratch/abc123}}
\begin{itemize}
\item{Visible equally from all nodes.}
\item{Larger, faster and no quotas.}
\item{Intended for job inputs and outputs.}
\item{{\color{red}Not backed up.}}
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Filesystems: Quotas}
\begin{itemize}
\item{quota}
\begin{semiverbatim}
\tiny
====================================================================================
Usage on /home (lfs quota -u abc123 /home):
====================================================================================
Disk quotas for user abc123 (uid 456):
     Filesystem  kbytes   quota   limit   grace   files   quota   limit   grace
          /home \only<1>{24513908}\only<2->{{\color{red}*43567687}}  41943040 47185920       -   75364       0       0       -
====================================================================================
Usage on /scratch (lfs quota -u abc123 /scratch):
====================================================================================
Disk quotas for user abc123 (uid 456):
     Filesystem  kbytes   quota   limit   grace   files   quota   limit   grace
       /lustre1 5467644384       0       0       - 3864823       0       0       -
...
\end{semiverbatim}
\item<1->{\alert{Aim to stay below the soft limit (\emph{quota}).}}
\item<2->{\alert{Once over the soft limit, you have 7 days grace to return below.}}
\item<3->{\alert{When the grace period expires, or you reach the hard limit (\emph{limit}), no more data can be written.}}
\item<4->{\alert{It is important to rectify an out of quota condition ASAP.}}
\end{itemize}
\end{frame}

\begin{frame}{Filesystems: Backups}
\begin{itemize}
\item<1->{Tape backups normally commence at 22:00 Monday -- Saturday.}
\item<2->{{\color{red}They are not an undelete - take care when deleting.}}
\item<3->{Successful restoration depends on:}
\begin{itemize}
\item{The file having existed long enough to have been backed up at all.}
\item{The last good version existing in a current backup.}
\item<4->{\color{red}Request restoration as soon as possible with \emph{location} and \emph{exact time of loss}.}
\medskip
\visible<5->{\item{\color{purple}\huge Scratch files are not backed up.}}
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Filesystems: Automounter}
\begin{itemize}
\item{Directories under /scratch are \alert{automounted}.}
\item{They only appear under /scratch when explicitly referenced.}
\item{Thus when browsing /scratch may appear too empty\hfill\\
\qquad\alert{--- use \emph{ls} or \emph{cd} to reference /scratch/abc123 explicitly.}}
\end{itemize}
\end{frame}

\begin{frame}{Filesystems: Permissions}
\begin{itemize}
\item{\color{red}Be careful and if unsure, please ask support@hpc.}
\begin{itemize}
\item{Can lead to \alert{accidental destruction} of your data or \alert{account compromise}.}
\end{itemize}
\item{Avoid changing the permissions on your home directory.}
\begin{itemize}
\item{Files under /home are particularly security sensitive.}
\item{Easy to break passwordless communication between nodes.}
\end{itemize}
\end{itemize}
\end{frame}

\section{Software}
\begin{frame}{Using HPC: Software}
\begin{itemize}
\item{Free software accompanying \alert{Red Hat Enterprise 6} is (or can be) provided.}
\item{Other software (free and non-free) is available via \alert{modules}.}
\item{Some proprietary software may not be generally accessible.}
\item{See \alert{http://www.hpc.cam.ac.uk/user/software.html}.}
\item{New software may be possible to provide on request.}
\item{\alert{Self-installed software must be properly licensed.}}
\end{itemize}
\end{frame}

\subsection{Environment Modules}
\begin{frame}[fragile]{User Environment: Environment Modules}
\begin{itemize}
\item{Modules load or unload additional software packages.}
\item{Some are \alert{required} and automatically loaded on login.}
\item{Others are optional extras, or possible replacements for other modules.}
\item{\alert{Beware} unloading default modules in $\tilde{}\text{/.bashrc}$.}
\item{\alert{Beware} setting environment variables such as PATH and LD\_LIBRARY\_PATH in $\tilde{}\text{/.bashrc}$.}
\end{itemize}
\end{frame}

\subsection{Environment Modules}
\begin{frame}[fragile]{User Environment: Environment Modules}
\begin{itemize}
\item{Currently loaded:}
\begin{semiverbatim}
\scriptsize
module list
Currently Loaded Modulefiles:
  1) dot                     6) intel/impi/4.1.3.045   11) default-impi
  2) scheduler               7) global                 12) cluster-tools/2.0.5
  3) java/jdk1.7.0_60        8) intel/cce/12.1.10.319  13) use.own
  4) turbovnc/1.1            9) intel/fce/12.1.10.319  14) bacula/5.2.13
  5) vgl/2.3.1/64           10) intel/mkl/10.3.10.319
\end{semiverbatim}
\medskip
\item{Available:}
\begin{semiverbatim}
\scriptsize
module av
\end{semiverbatim}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{User Environment: Environment Modules}
\begin{itemize}
\item{Show:}
\begin{semiverbatim}
\tiny
module show castep/impi/7.0.3
-------------------------------------------------------------------
/usr/local/Cluster-Config/modulefiles/castep/impi/7.0.3:

module-whatis    adds CASTEP 7.0.3 (Intel MPI) to your environment 

Note that this software is restricted to registered users.

prepend-path     PATH /usr/local/Cluster-Apps/castep/impi/7.0.3/bin:/usr/local/...
-------------------------------------------------------------------
\end{semiverbatim}
\medskip
\item{Load:}
\begin{semiverbatim}
\scriptsize
module load castep/impi/7.0.3
\end{semiverbatim}
\medskip
\item{Unload:}
\begin{semiverbatim}
\scriptsize
module unload castep/impi/7.0.3
\end{semiverbatim}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{User Environment: Environment Modules}
\begin{itemize}
\item{Purge:}
\begin{semiverbatim}
\scriptsize
module purge
\end{semiverbatim}
\smallskip
\item{Defaults:}
\begin{semiverbatim}
\scriptsize
module show default-impi
module unload default-impi
module load default-impi-LATEST
\end{semiverbatim}
\medskip
\item{Run time environment must match compile time.}
\end{itemize}
\end{frame}

\subsection{Compilers}
\begin{frame}[fragile]{User Environment: Compilers}
\begin{description}
\item[Intel:]{\alert{icc}, \alert{icpc}, \alert{ifort} (recommended)}
\begin{semiverbatim}
\scriptsize
icc -O3 -xHOST -ip code.c -o prog
mpicc -O3 -xHOST -ip mpi_code.c -o mpi_prog
\end{semiverbatim}
\smallskip
\item[GCC:]{\alert{gcc}, \alert{g++}, \alert{gfortran}}
\begin{semiverbatim}
\scriptsize
gcc -O3 -mtune=native code.c -o prog
mpicc -cc=gcc -O3 -mtune=native mpi_code.c -o mpi_prog
\end{semiverbatim}
\smallskip
\item[PGI:]{\alert{pgcc}, \alert{pgCC}, \alert{pgf90}}
\begin{semiverbatim}
\scriptsize
pgcc -O3 -tp=sandybridge code.c -o prog
mpicc -cc=pgcc -O3 -tp=sandybridge mpi_code.c -o mpi_prog
\end{semiverbatim}
\end{description}
\end{frame}

\section{Job Submission}
\begin{frame}{Using HPC: Job Submission}
\begin{itemize}
\item{Compute resources are managed by a scheduler:\hfill\\\qquad\alert{SLURM}/PBS/SGE/LSF/\ldots}
\item{Jobs are submitted to the scheduler\hfill\\\qquad --- analogous to submitting jobs to a print queue.}
\end{itemize}
\end{frame}

\begin{frame}{Using HPC: Job Submission}
\begin{itemize}
\item{Jobs are submitted from the login nodes\hfill\\\qquad  --- not themselves managed by the scheduler.}
\item{Jobs may be either non-interactive (\alert{batch}) or \alert{interactive}.}
\pause
\item{\alert{Batch} jobs run a shell script on the first of a list of allocated nodes.}
\item{\alert{Interactive} jobs provide a command line on the first of a list of allocated nodes.}
\end{itemize}
\end{frame}

\begin{frame}{Using HPC: Job Submission}
\begin{itemize}
\item{The HPCS moved away from Torque (a form of PBS) to SLURM in February 2014.}
\item{The HPCS dedicates \alert{entire} nodes to each job\hfill\\
\qquad --- the owner receives \alert{exclusive} access.}
\item{Template submission scripts are available under\hfill\\
\qquad \alert{/usr/local/Cluster-Docs/SLURM}.}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Job Submission: Using SLURM or PBS}
\begin{itemize}
\item{SLURM}
\begin{semiverbatim}
\scriptsize
[abc123@login]$ sbatch slurm_submission_script
Submitted batch job {\color{red}790299}
\end{semiverbatim}
\medskip
\item{PBS (Torque, OpenPBS, PBS Pro)}
\begin{semiverbatim}
\scriptsize
[abc123@login]$ qsub pbs_submission_script
{\color{red}790299}.master.cluster
\end{semiverbatim}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Job Submission: Show Queue}
\begin{itemize}
\item{SLURM}
\begin{semiverbatim}
\tiny
[abc123@login]$ squeue -u abc123
             JOBID PARTITION     NAME     USER  ST       TIME  NODES NODELIST(REASON)
            {\color{red}790299} sandybrid     Test3  abc123 PD       0:00      8 (Resources)
            790290 sandybrid     Test2  abc123  R   27:56:10      8 sand-6-[38-40],sand-7-[27-31]
\end{semiverbatim}
\medskip
\item{PBS (Torque, OpenPBS, PBS Pro)}
\begin{semiverbatim}
\tiny
[abc123@login]$ qstat -u abc123
Job ID               Username    Queue    Jobname          SessID NDS   TSK    Memory Time  S Time
-------------------- ----------- -------- ---------------- ------ ----- ------ ------ ----- - -----
790290.master.cl     abc123      tesla    Test2              5519     8     32 248000 36:00 R 27:56
790281.master.cl     abc123      tesla    Test1             31905     4     16 124000 36:00 C 26:17
{\color{red}790299}.master.cl     abc123      tesla    Test3               --      8     32 248000 36:00 Q   --
\end{semiverbatim}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Job Submission: Monitor Job}
\begin{itemize}
\item{SLURM}
\begin{semiverbatim}
\scriptsize
[abc123@login]$ scontrol show job={\color{red}790299}
\end{semiverbatim}
\medskip
\item{PBS (Torque, OpenPBS, PBS Pro)}
\begin{semiverbatim}
\scriptsize
[abc123@login]$ qstat -f {\color{red}790299}
\end{semiverbatim}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Job Submission: Cancel Job}
\begin{itemize}
\item{SLURM}
\begin{semiverbatim}
\scriptsize
[abc123@login]$ scancel {\color{red}790299}
\end{semiverbatim}
\medskip
\item{PBS (Torque, OpenPBS, PBS Pro)}
\begin{semiverbatim}
\scriptsize
[abc123@login]$ qdel {\color{red}790299}
\end{semiverbatim}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Job Submission: Scripts}
\begin{itemize}
\item{SLURM\hfill\\
See \alert{slurm\_submit.sandybridge}, \alert{slurm\_submit.tesla}.}
\begin{semiverbatim}
\tiny
#!/bin/bash
#! Name of the job:
{\color<2->{red}#SBATCH} -J darwinjob
#! Which project should be charged:
{\color<2->{red}#SBATCH} -A CHANGEME
#! How many whole nodes should be allocated?
{\color<2->{red}#SBATCH} --nodes=2
#! How many (MPI) tasks will there be in total? (<= nodes*16)
{\color<2->{red}#SBATCH} --ntasks=32
#! How much wallclock time will be required?
{\color<2->{red}#SBATCH} --time=02:00:00
#! Select partition:
{\color<2->{red}#SBATCH} -p sandybridge
...
\end{semiverbatim}
\item<2->{{\color{red}\#SBATCH} lines are \emph{structured comments}\hfill\\
\qquad --- correspond to sbatch command line options.}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Job Submission: Scripts}
\begin{itemize}
\item{PBS (Torque, OpenPBS, PBS Pro)}
\begin{semiverbatim}
\tiny
#!/bin/bash 
#! Name of the job:
{\color<2->{red}#PBS} -N darwinjob
#! Which project should be charged:
{\color<2->{red}#PBS} -A CHANGEME
#! How many nodes, cores per node, memory and wall-clock time should be allocated?
{\color<2->{red}#PBS} -l nodes=8:ppn=16,mem=512000mb,walltime=02:00:00
#! Select queue:
{\color<2->{red}#PBS} -q sandybridge
...
\end{semiverbatim}
\item<2->{{\color{red}\#PBS} lines are \emph{structured comments}\hfill\\
\qquad --- correspond to qsub command line options.}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Job Submission: Accounting Commands [HPCS]}
\begin{itemize}
\item{How many core hours available do I have?}
\begin{semiverbatim}
\tiny
mybalance

User            Usage |        Account     Usage | Account Limit Available (CPU hrs)
----------  --------- + -------------- --------- + ------------- ---------
abc123             18 |          STARS       171 |       100,000    {\color{red}99,829}
abc123             18 |      STARS-SL2        35 |       101,000   {\color{red}100,965}
abc123            925 |         BLACKH    10,634 |       166,667   {\color{red}156,033}
\end{semiverbatim}
\smallskip
\item{How many core hours does some other project or user have?}
\begin{semiverbatim}
\tiny
gbalance -p HALOS

User           Usage |   Account     Usage | Account Limit Available (CPU hrs)
---------- --------- + --------- --------- + ------------- ---------

pq345              0 |     HALOS   317,656 |       600,000   {\color{red}282,344}
xyz10         11,880 |     HALOS   317,656 |       600,000   {\color{red}282,344}

(Use -u for user.)
\end{semiverbatim}
\smallskip
\item{List all jobs charged to a project/user between certain times:}
\begin{semiverbatim}
\Tiny
gstatement -p HALOS  -u xyz10 -s "2014-01-01-00:00:00" -e "2014-01-20-00:00:00" 
       JobID      User   Account  JobName  Partition                 End      NCPUS CPUTimeRAW ExitCode      State 
------------ --------- ---------- -------- ---------- ------------------- ---------- ---------- -------- ---------- 
14505            xyz10    halos       help sandybrid+ 2014-01-07T12:59:40         16         32      0:9  COMPLETED 
14506            xyz10    halos       help sandybrid+ 2014-01-07T13:00:11         16         48      2:0     FAILED
...
\end{semiverbatim}
\end{itemize}
\end{frame}


\subsection{Single Node Jobs}
\begin{frame}[fragile]{Job Submission: Single Node Jobs}
\begin{itemize}
\item{Serial jobs requiring large memory, or OpenMP codes.}
\begin{semiverbatim}
\scriptsize
#!/bin/bash
\ldots
#SBATCH --nodes=1
\ldots
\uncover<2->{{\color{red}export OMP\_NUM\_THREADS=\only<2>{16}\only<3>{8 }   # For OpenMP across \only<2>{16}\only<3>{8} cores.}}
\$application \$options
\ldots
\end{semiverbatim}
\end{itemize}
\end{frame}

\subsection{MPI Jobs}
\begin{frame}[fragile]{Job Submission: MPI Jobs}
\begin{itemize}
\item{Parallel job across multiple nodes.}
\begin{semiverbatim}
\scriptsize
#!/bin/bash
\ldots
#SBATCH --nodes={\color{red}4}
#SBATCH --ntasks=\alert{\only<1>{64}\only<2->{32}}     # \only<1>{i.e.\ {\color[rgb]{0,0.8,0}16}}\only<2->{i.e.\ {\color[rgb]{0,0.8,0} 8}}x{\color{red}4} MPI tasks in total.
\ldots
mpirun\only<2->{ -ppn {\color[rgb]{0,0.8,0}8}} -np \alert{\only<1>{64}\only<2->{32}} \$application \$options
\ldots
\end{semiverbatim}
\item<3->{\small SLURM-aware MPI launches remote tasks via SLURM.}
\item<3->{\small The template script uses \$SLURM\_TASKS\_PER\_NODE to set PPN.}
\end{itemize}
\end{frame}

\subsection{Hybrid Jobs}
\begin{frame}[fragile]{Job Submission: Hybrid Jobs}
\begin{itemize}
\item{Parallel jobs using both MPI and OpenMP.}
\begin{semiverbatim}
\scriptsize
#!/bin/bash
\ldots
#SBATCH --nodes={\color{red}4}
#SBATCH --ntasks=\alert{32}     # i.e.\ {\color[rgb]{0,0.8,0} 8}x{\color{red}4} MPI tasks in total.
\ldots
{\color{brown}export OMP\_NUM\_THREADS=2   # i.e.\ 2 threads per MPI task.}
mpirun -ppn {\color[rgb]{0,0.8,0}8} -np \alert{32} \$application \$options
\ldots
\end{semiverbatim}
\item<2->{\small This job uses \alert{64 cores} (each MPI task splits into 2 OpenMP threads).}
\item<3->{\small \alert{We always charge for all cores.}}
\end{itemize}
\end{frame}

\subsection{High Throughput Jobs}
\begin{frame}[fragile]{Job Submission: High Throughput Jobs}
\begin{itemize}
\item{Multiple serial jobs across multiple nodes.}
\item{Use \alert{srun} to launch processes within a job.}
\begin{semiverbatim}
\scriptsize
#!/bin/bash
\ldots
#SBATCH --nodes=4
\ldots
cd directory\_for\_job1
\alert{srun} {\color<3>{red}--exclusive} {\color<2>{red}-n 1} \$application \$options\_for\_job1 > output 2> error {\color<4>{red}&}
cd directory\_for\_job2
\alert{srun} {\color<3>{red}--exclusive} {\color<2>{red}-n 1} \$application \$options\_for\_job2 > output 2> error {\color<4>{red}&}
...
cd directory\_for\_job64
\alert{srun} {\color<3>{red}--exclusive} {\color<2>{red}-n 1} \$application \$options\_for\_job64 > output 2> error {\color<4>{red}&}
{\color<5>{red}wait}
\end{semiverbatim}
\end{itemize}
\end{frame}

\subsection{Interactive Jobs}
\begin{frame}[fragile]{Job Submission: Interactive [HPCS]}
\begin{itemize}
\item{Compute nodes are accessible via SSH \alert{while you have a job running on them}.}
\pause
\item{Alternatively, submit an interactive job:}
\begin{semiverbatim}
\alert{sintr -A MYPROJECT -p sandybridge -N2 -t 2:0:0}
\end{semiverbatim}
\medskip
\pause
\item{Within the window (screen session):}
\begin{itemize}
\item[$\ast$]{Launches a shell on the first node (when the job starts).}
\item[$\ast$]{Graphical applications should display correctly.}
\item[$\ast$]{Create new shells with \alert{ctrl-a c}, navigate with \alert{ctrl-a n} and \alert{ctrl-a p}.}
\item[$\ast$]{\alert{ssh} or \alert{srun} can be used to start processes on any nodes in the job.}
\item[$\ast$]{SLURM-aware MPI will do this automatically.}
\end{itemize}
\end{itemize}
\end{frame}


\subsection{Array Jobs}
\begin{frame}[fragile]{Job Submission: Array Jobs}
\begin{itemize}
\item{\color{red}This feature varies between versions.}
\item{Used for submitting and managing large sets of similar jobs.}
\item{SLURM}
\begin{semiverbatim}
\scriptsize
[abc123@login]$ sbatch --array=\only<1,2>{{\color{red}1-7}}\only<2>{{\color{red}:2}}\only<3->{{\color{red}1,3,5,7}} -A STARS-SL2 submission\_script
Submitted batch job {\color[rgb]{0,0.6,0}791609}
\tiny
\uncover<4->{[abc123@login-sand2]$ squeue -u abc123
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          {\color[rgb]{0,0.6,0}791609}\_{\color{red}1} sandybrid      hpl    abc123  R       0:06      1 sand-6-32
          {\color[rgb]{0,0.6,0}791609}\_{\color{red}3} sandybrid      hpl    abc123  R       0:06      1 sand-6-37
          {\color[rgb]{0,0.6,0}791609}\_{\color{red}5} sandybrid      hpl    abc123  R       0:06      1 sand-6-59
          {\color[rgb]{0,0.6,0}791609}\_{\color{red}7} sandybrid      hpl    abc123  R       0:06      1 sand-7-27
}
\end{semiverbatim}
\uncover<5->{\centerline{{\color[rgb]{0,0.6,0}791609}\_{\color{red}1}, {\color[rgb]{0,0.6,0}791609}\_{\color{red}3}, {\color[rgb]{0,0.6,0}791609}\_{\color{red}5}, {\color[rgb]{0,0.6,0}791609}\_{\color{red}7}}}
\smallskip
\uncover<6->{\centerline{i.e.\ \$\{{\color[rgb]{0,0.6,0}SLURM\_ARRAY\_JOB\_ID}\}\_\$\{{\color{red}SLURM\_ARRAY\_TASK\_ID}\}}}
\smallskip
\uncover<7->{\leftline{\small SLURM\_ARRAY\_JOB\_ID${}={}$SLURM\_JOBID for the first element.}}
\smallskip
\uncover<8->{\leftline{\small Updates can be applied to single array elements only.}}
\smallskip
\uncover<9->{\leftline{\small Cancel, hold, requeue on SLURM\_ARRAY\_JOB\_ID operate on the entire array.}}
\end{itemize}
\end{frame}

\subsection{Scheduling Top Tips}
\begin{frame}{Job Submission: Scheduling Top Dos \& Don'ts}
\begin{itemize}
\item{\textbf{Do \ldots}}
\begin{itemize}
\item{Give reasonably accurate wall times (allows \alert{backfilling}).}
\item{Check your balance occasionally (\alert{mybalance}).}
\item{Test on a small scale first.}
\item{Implement \alert{checkpointing} (reduces resource wastage).}
\end{itemize}
\medskip
\item{\textbf{Don't \ldots}}
\begin{itemize}
\item{Request more cores than you need\hfill\\
\qquad --- you will wait longer and be charged anyway.}
\item{Cancel jobs unnecessarily\hfill\\
\qquad ---  priority increases over time.}
\end{itemize}
\end{itemize}
\end{frame}


\end{document}


%Diagram of darwin/wilkes

%More on support and documentation
%Plug for unix command line course
%Passwords
%Editors
%man, info


